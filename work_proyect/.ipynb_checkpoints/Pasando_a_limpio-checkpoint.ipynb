{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Exploracion de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comenzamos exportando la tabla y las librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Operaciones'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-00a770fe4010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mOperaciones\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Imputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_raw.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Operaciones'"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import re\n",
    "from Operaciones import *\n",
    "os.chdir(\"../Imputs\")\n",
    "dataset=pd.read_csv(\"data_raw.csv\", engine = \"python\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25723, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Con esta info nos hacemos una idea del número de columnas y filas y nos damos cuenta que no todas las columnas tienen el mismo número de filas\n",
    "\n",
    "*Vemos en columnas que hay nombres de columnas con espacios de más \n",
    "\n",
    "*Todas las columnas son object excepto dos de ellas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para tener una visión más clara imprimimos la tabla**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width',500)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Existen espacios en las celdas que estropean el diseño \n",
    "\n",
    "*Case Number, Case Number.1 y Case Number.2 dan información similar\n",
    "\n",
    "*Las columnas de pdf, href e investigator source, no aportan información de valor para el análisis\n",
    "\n",
    "*Case Number que es una de las columnas con más filas, tiene en la cola un aespecie de indíce 0\n",
    "\n",
    "*En name hay elementos que deberían ir en Sex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comprobamos la cantidad de Nam con los que nos encontramos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Vemos que las columnas Unnamed 22 y 23 tienen casi todos los valores NaN (con respecto a los 5992 que vemos en info\n",
    "\n",
    "*La columna Time, tiene más de la mitad de los valores NaN\n",
    "\n",
    "*La columna Age y Species se acercan a la mitad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chequear si las columnas son únicas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Parece interesante que haya 9 valores diferentes en Y/N que solo debería tener dos opciones\n",
    "\n",
    "*En Ages, hay 152 opciones...nadie vive tanto\n",
    "\n",
    "*lo mismo , sucede en Sex, hay 6 tipos, y no existen tantos sexos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Limpieza de datos tras un primer contacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape  #numero de valores antes de borrar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Borramos todos los NaN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(how='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape  #numero despues de borrar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cambiar los datos a tipo objet para poder utilizar Redex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Year']=dataset['Year'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solventar los espacios de las columnas que vimos en columns renombrando**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.rename(columns={\"Sex \":\"Sex\", \"Species \":\"Species\"}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Borrar espacios de las celdas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ya podemos borrar al tener todo en object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.applymap(lambda x: x.strip() if type(x)==str else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparar Number Case con Number Case 1, y Number Case 2, para ver si tienen valores iguales o parecidos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Crearemos una columna que será True si Case y Case Number 1 son iguales y False si son diferentes\n",
    "*Haremos lo mismo con Case Number y Case Number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Casenumber_subset = dataset[['Case Number','Case Number.1','Case Number.2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "comparing_cols(dataset[\"Case Number\"],dataset[\"Case Number.1\"],dataset[\"Case Number.2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Vamos a comprobar los datos que son iguales entre Case Numer y Case Numer 1 vs Case Numer y Case Number 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Podemos ver entonces que Case Number 1, tiene mas diferencias, pero parecidas a Case Numer 2.Teniendo en cuenta que Case Number tiene  6297( respecto a 6278 y 6278 ), no dista mucho del numero de valores. Por lo tanto borramos tanto Case Number 1, como Case number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop([\"Case Number.1\",\"Case Number.2\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Volvemos a quitar los espacios, dado que antes para toda la tabla no se nos han eliminado.\n",
    "ESta vez solo lo haremos en l acolumna Case Number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Case Number\"].apply(lambda x: x.strip() if type(x)==str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Case Number\"].tolist() #estan con letras aleatorias tras las fechas. podremos fecha +a si no tiene letra o acaba en R\n",
    "                                #y fecha +b,c,d si tiene esas letras para indicar que es el segundo,tercer,o cuarto caso de esa fecha\n",
    "                                #se espera emberllecer la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    filter_data = dataset.loc[index, \"Case Number\"]\n",
    "    filter_data = re.sub('[^0-9a-zA-Z]+', '.',str(filter_data))\n",
    "    if filter_data[-1] =='R':         \n",
    "        filet_new_data =str(filter_data[:5]) + str(filter_data[5:7])+ str(filter_data[7:9]) + str(\".\") + str(\"a\")\n",
    "        dataset.loc[index, \"Case Number\"] = filet_new_data\n",
    "    elif len(filter_data) <=11:       \n",
    "        filet_new_data = str(filter_data[:-1])+ str(\".\")+str(\"a\")\n",
    "        dataset.loc[index, \"Case Number\"] = filet_new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Case Number\"].tolist() #comprobamos...bien , se ha cambiado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chequeamos si los tres valores que quedan en Unnamed 22 y 23  tienen sentido y... decidimos borrar ambas columnas, pues Teramo, change filename y stopped here no aporta valor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_un_22 = dataset[~dataset[\"Unnamed: 22\"].isnull()|~dataset[\"Unnamed: 23\"].isnull()][[\"Unnamed: 22\",\"Unnamed: 23\"]]\n",
    "df_un_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop([\"Unnamed: 22\",\"Unnamed: 23\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Como hemos visto que hay demasidas opciones de datos vamos a unificarlos en 3: M,F,Undefined**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(dataset[\"Sex\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset[\"Sex\"] = dataset[\"Sex\"].apply(sex_def)\n",
    "\n",
    "dataset[\"Sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(dataset['Fatal (Y/N)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Con Fatal (Y/N) pasaba algo parecido, demasiadas opciones. Las reagrupamos en tres:Y,N, Unknown**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset[\"Fatal (Y/N)\"] = dataset[\"Fatal (Y/N)\"].apply(muertes_si_no)\n",
    "\n",
    "dataset[\"Fatal (Y/N)\"].head(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hemos visto que en Time había gran cantidad de Nan,y los valores salvados son insignificantes con respecto al conjunto de datos de la columna. Por lo tanto, borraremos la columna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop([\"Time\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Con Species pasa parecido, las mejor definidas serían White Shark, Tiger Shark, pero no son suficientes para obtener un dato eficiente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop([\"Species\"],axis=1, inplace=True)\n",
    "\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name hemos dicho que no aportaba valor, asi que tambien lo borramos**\n",
    "\n",
    "**Nos pasa lo mismo con pdf,href e Investigator Source que no nos sirven de nada para el análisis**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop([\"Name\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = [6,12,13,14,15,16]\n",
    "dataset=dataset.drop(dataset.columns[cols], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset['Age'] = pd.to_numeric(dataset['Age'].replace(',','', regex=True), errors='coerce', downcast='float')\n",
    "dataset['Age'] = pd.to_numeric(dataset['Age'], errors='coerce') #no se puede pasar un string a int de una\n",
    "dataset['Age'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Limpiando las columnas restantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**En la columna Age extraer los número del string para unificar la columna**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tambien le daremos el valor 0 a los datos por encima de 100, porque nadie vive tanto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Age'] = dataset['Age'].apply(lambda x: 0 if x > 100 else str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Vemos que ha cambiado a 87 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**En Country, aplicamos mayúsculas a los valores del atributo \"Country\" y eliminamos los espacios al principio y al final del string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset['Country']=dataset['Country'].str.upper()\n",
    "dataset['Country']=dataset['Country'].str.rstrip()\n",
    "dataset['Country']=dataset['Country'].str.lstrip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploramos la columna Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Date\"].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Date\"].fillna(\" \", inplace = True) #super importante, me daba un error de que tenía floats, y es que los nulos estan consierados floats\n",
    "date = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "for index, row in dataset.iterrows():\n",
    "    data_date = dataset.loc[index, \"Date\"]# hago un loc de date\n",
    "    data_date=data_date.replace(r'\\D','') # todo lo que no sea digito lo reemplazo por nada ¡¡¡¡no va!!                                     #data_date=data_date.fillna(\" \", inplace = True) por que no me deja hacerlo ?\n",
    "    \n",
    "\n",
    "    \n",
    "    for num, months in date.items(): #vamos a reeplazar los meses por numero\n",
    "        if str(months) in data_date:\n",
    "            data_date=data_date.replace(str(months),str(num))\n",
    "            dataset.loc[index, \"Date\"]= data_date  \n",
    "                \n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "dataset[\"Date\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#ESTO ES UN INTENTO DE LIMPIAR Y PÀSAR A FORMATO FECHA PERO NO LO HE CONSEGUIDO\n",
    "\n",
    "weird_dates = []\n",
    "for index, row in dataset.iterrows():\n",
    "    data_date= dataset.loc[index,\"Date\"]\n",
    "\n",
    "    match = re.search(r\"(\\d+[-/]\\d+[-/]\\d+)\", data_date) #todo lo que tenga un formato diferente a un formato fecha\n",
    "                                                         #lo meto en una lista llamada weird_dates para ver si podemos salvar mas\n",
    "                                                        #ya que aun sin formato de fecha parecen ser fechas mal escritas\n",
    "    if match is not None:\n",
    "        weird_dates.append(\"\")\n",
    "        # print(match.group(0))\n",
    "\n",
    "    else:\n",
    "        weird_dates.append(data_date)                     #¡en efecto, nada interesante!\n",
    "        #print(weird_dates)\n",
    " \n",
    "\n",
    "#AQUI SEGUÍA EL INTENTO-------------------------------------------------\n",
    "\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    filter_data = dataset.loc[index, \"Date\"]\n",
    "    \n",
    "    if filter_data[5] =='-':         \n",
    "        filet_new_data =str(filter_data[:2]) + str(\"-\")+ str(\"0\")+ str(filter_data[2:5])+str(\"-\")+ str(filter_data[5:9])\n",
    "        dataset.loc[index, \"Date\"] = filet_new_data\n",
    "        \n",
    "        \n",
    "#AQUÍ SEGUÍA EL ERROR AL NO COINCIDIR DE FORMA EXACTA CON EL FORMATO FECHA. CON QUE SEA 00.0.0000 Y NO 00.00.00. DA ERROR\n",
    "\n",
    " # lo pasamos a formato fecha porque sera mas facil de esa forma extraer dia, mes y año en tres columnas \n",
    "dataset['Date'] = pd.to_datetime(dataset['Date'], format=\"%d/%m/%Y\")\n",
    "#df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Vemos que hay fechas completas mezcladas con años sueltos. Se me ocurre extraer los años que es lo único que nos interesa. Aunque ya tengamos otra columna year, esta parece más interesante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset[\"Year\"]=dataset[\"Date\"].str.extract(r\"([0-9]{4})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Year\"].value_counts().head(20) #Chequeamos que se han cambiado los años"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset['Year'] = pd.to_numeric(dataset['Year'].replace(',','', regex=True), errors='coerce', downcast='float')\n",
    "dataset['Year'] = pd.to_numeric(dataset['Year'], errors='coerce') #no se puede pasar un string a int de una\n",
    "dataset['Year'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Year\"]= dataset[\"Year\"].apply(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ahora sí, eliminamos la columna Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop([\"Date\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploramos la columna Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Vemos que hay diferentes tipos de datos donde Boating,Boat, Questionable, Sea Disaster junto on Invalid e puede resumir en desconocido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset['Type'] != \"Unprovoked\", \"Provoked\"] = \"Unknown\"\n",
    "dataset[\"Type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miremos la columna Injury**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Injury\"].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Salen datos muy distintos pero bastante completos. No la vamos a tocar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miramos la columna Activity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[\"Activity\"].value_counts().head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Vemos que algunas actividades no son deportes sino palabras random que se han introducido erroneamente. \n",
    "Es por eso que vamos a conservar solo aquellas palabras que tengan \"ing\", pues es la terminación de los deportes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Activity'] = dataset['Activity'].fillna('No Values')\n",
    "\n",
    "dataset[\"Activity\"]= get_ing(dataset[\"Activity\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Activity\"].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exportar a csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset=dataset[[\"Year\",\"Country\",\"Fatal (Y/N)\"]]\n",
    "small_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ruta = \"../Outputs/out_dataset.csv\"\n",
    "#dataset.to_csv(ruta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ¡Vamos a Analizar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decades_fatal_sum = dataset.groupby([\"Year\", \"Fatal (Y/N)\"]).agg({\"Fatal (Y/N)\":\"count\"})\n",
    "decades_fatal_sum.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decades_fatal_sum[\"%\"] =decades_fatal_sum.apply(lambda x:  100*x / x.sum())\n",
    "#decades.head(10).sort_values(by=\"%\")\n",
    "decades_fatal_sum  = decades_fatal_sum .xs(\"Yes\", level = \"Fatal (Y/N)\", drop_level = False)\n",
    "decades_fatal_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decades_fatal_sum.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_total = dataset.groupby([\"Country\"]).agg({\"Country\":\"count\"})\n",
    "output_total.append(output_total.agg(['sum']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_fatal =dataset.groupby([\"Country\", \"Fatal (Y/N)\"]).agg({\"Country\":\"count\"})\n",
    "output_fatal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
